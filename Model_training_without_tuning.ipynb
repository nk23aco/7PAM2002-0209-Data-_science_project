{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Sy-PtXyVEZe_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/weather_2016_2020_daily.csv\", parse_dates=['Date'], index_col='Date')\n",
        "\n",
        "# Sort and fill missing values if any\n",
        "df.sort_index(inplace=True)\n",
        "df.fillna(method='ffill', inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXbHsw_7Ew7m",
        "outputId": "f8adf50b-4904-4f6a-dc8f-85157b4bd85d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-81b513a33f3b>:6: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df.fillna(method='ffill', inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Engineering: Lag Features\n",
        "for lag in range(1, 8):\n",
        "    df[f'Precipit_lag_{lag}'] = df['Precipit'].shift(lag)\n",
        "\n",
        "# Rolling window features\n",
        "df['Precipit_3d_avg'] = df['Precipit'].rolling(window=3).mean()\n",
        "df['Precipit_7d_avg'] = df['Precipit'].rolling(window=7).mean()\n",
        "df['Precipit_7d_std'] = df['Precipit'].rolling(window=7).std()\n",
        "\n",
        "# Time-based features\n",
        "df['day_of_year'] = df.index.dayofyear\n",
        "df['month'] = df.index.month\n",
        "df['weekday'] = df.index.weekday\n"
      ],
      "metadata": {
        "id": "quX46BglE4ZP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows with NaN\n",
        "df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "fKjAl8L8E7OR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define features and target\n",
        "X, y = df.drop(columns=['Precipit']), df['Precipit']"
      ],
      "metadata": {
        "id": "Jll1GAveE9Wz"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data (80% Train, 20% Test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False, random_state=42)\n",
        "\n",
        "# Save training columns.\n",
        "X_train_columns = X_train.columns.tolist()\n",
        "\n",
        "# Feature Scaling using StandardScaler\n",
        "scaler_std = StandardScaler()\n",
        "X_train_scaled = scaler_std.fit_transform(X_train)\n",
        "X_test_scaled = scaler_std.transform(X_test)"
      ],
      "metadata": {
        "id": "pFFmSWqaFAlO"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Implementations**"
      ],
      "metadata": {
        "id": "EYcd3pWgGngy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = df['Precipit']\n",
        "exog = df[['Precipit_lag_1', 'Precipit_3d_avg', 'day_of_week']]\n",
        "\n",
        "train_size = int(len(df) * 0.8)\n",
        "y_train, y_test = y[:train_size], y[train_size:]\n",
        "exog_train, exog_test = exog[:train_size], exog[train_size:]\n",
        "\n",
        "\n",
        "sarimax_model_default = SARIMAX(y_train, exog=exog_train, order=(1, 0, 1), seasonal_order=(0, 0, 1, 7))\n",
        "results_default = sarimax_model_default.fit(disp=False)\n",
        "y_pred_default = results_default.forecast(steps=len(y_test), exog=exog_test)\n",
        "\n",
        "mse_default = mean_squared_error(y_test, y_pred_default)\n",
        "mae_default = mean_absolute_error(y_test, y_pred_default)\n",
        "r2_default = r2_score(y_test, y_pred_default)\n",
        "\n",
        "mse_default, mae_default, r2_default"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZNgbsbbFD3j",
        "outputId": "c23e9d96-3af2-402c-e306-4767227cec77"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.11/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.11/dist-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
            "/usr/local/lib/python3.11/dist-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
            "  return get_prediction_index(\n",
            "/usr/local/lib/python3.11/dist-packages/statsmodels/tsa/base/tsa_model.py:837: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
            "  return get_prediction_index(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.046879168276924246, 0.10383254410456537, 0.49286387375333207)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# Initialize baseline RF model\n",
        "rf_baseline = RandomForestRegressor(random_state=42)\n",
        "rf_baseline.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_rf_base = rf_baseline.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate\n",
        "mse_rf_base = mean_squared_error(y_test, y_pred_rf_base)\n",
        "mae_rf_base = mean_absolute_error(y_test, y_pred_rf_base)\n",
        "r2_rf_base = r2_score(y_test, y_pred_rf_base)\n",
        "\n",
        "print(\"\\nRandom Forest (Before Tuning):\")\n",
        "print(f\"MSE: {mse_rf_base:.4f}, MAE: {mae_rf_base:.4f}, R²: {r2_rf_base:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkzX5yRoFVN1",
        "outputId": "cfe8b659-1931-4c32-a4e4-f6ad68b45819"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Random Forest (Before Tuning):\n",
            "MSE: 0.0091, MAE: 0.0372, R²: 0.9012\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import StackingRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# Define base models (default settings)\n",
        "base_models = [\n",
        "    ('rf', RandomForestRegressor(random_state=42)),\n",
        "    ('gb', GradientBoostingRegressor(random_state=42))\n",
        "]\n",
        "\n",
        "# Stacking Regressor\n",
        "stacking_model = StackingRegressor(\n",
        "    estimators=base_models,\n",
        "    final_estimator=RandomForestRegressor(random_state=42)\n",
        ")\n",
        "\n",
        "# Train\n",
        "stacking_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred_stack = stacking_model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate\n",
        "mse_stack = mean_squared_error(y_test, y_pred_stack)\n",
        "mae_stack = mean_absolute_error(y_test, y_pred_stack)\n",
        "r2_stack = r2_score(y_test, y_pred_stack)\n",
        "\n",
        "print(f\"Stacking Regressor (Before Tuning) - MSE: {mse_stack:.4f}, MAE: {mae_stack:.4f}, R²: {r2_stack:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SaiEqJNF5MZ",
        "outputId": "b665e8bf-a1de-48c8-ec2b-b65e82047eb5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking Regressor (Before Tuning) - MSE: 0.0056, MAE: 0.0301, R²: 0.9396\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import numpy as np\n",
        "\n",
        "# Normalize data\n",
        "scaler = MinMaxScaler()\n",
        "scaled_data = scaler.fit_transform(df)\n",
        "\n",
        "# Create sequences\n",
        "def create_sequences(data, time_steps=14):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - time_steps):\n",
        "        X.append(data[i:i + time_steps])\n",
        "        y.append(data[i + time_steps, 0])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "time_steps = 14\n",
        "train_size = int(len(scaled_data) * 0.8)\n",
        "train, test = scaled_data[:train_size], scaled_data[train_size:]\n",
        "X_train, y_train = create_sequences(train, time_steps)\n",
        "X_test, y_test = create_sequences(test, time_steps)\n",
        "\n",
        "# Build a basic LSTM model (no tuning)\n",
        "model = Sequential([\n",
        "    LSTM(64, activation='relu', return_sequences=True, input_shape=(time_steps, X_train.shape[2])),\n",
        "    Dropout(0.2),\n",
        "    LSTM(32, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(1)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train model\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping], verbose=0)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(X_test)\n",
        "y_test_inv = scaler.inverse_transform(np.c_[y_test, np.zeros((y_test.shape[0], scaled_data.shape[1]-1))])[:, 0]\n",
        "y_pred_inv = scaler.inverse_transform(np.c_[y_pred, np.zeros((y_pred.shape[0], scaled_data.shape[1]-1))])[:, 0]\n",
        "\n",
        "# Evaluate\n",
        "mse = mean_squared_error(y_test_inv, y_pred_inv)\n",
        "mae = mean_absolute_error(y_test_inv, y_pred_inv)\n",
        "r2 = r2_score(y_test_inv, y_pred_inv)\n",
        "print(f\"LSTM (Without Tuning) - MSE: {mse:.4f}, MAE: {mae:.4f}, R²: {r2:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PA5gViRGGKtJ",
        "outputId": "8422e69c-dc69-4e24-ef1c-81ec26eb3a3b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step\n",
            "LSTM (Without Tuning) - MSE: 20.4777, MAE: 2.8999, R²: 0.7160\n"
          ]
        }
      ]
    }
  ]
}